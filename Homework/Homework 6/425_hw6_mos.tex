\documentclass[12pt]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{fancyhdr,latexsym,amssymb,amsmath,graphicx}
\usepackage{algorithm}
\usepackage{cancel}
\usepackage[noend]{algpseudocode}
\usepackage[pdftex]{hyperref}
\pagestyle{fancy}
\usepackage[parfill]{parskip} % Do not indent between empty lines
\usepackage{mathtools}
\usepackage{nicematrix}
\usepackage{xfrac}
\usepackage{bm}
\usepackage{esvect}

% For the \set notation
\usepackage{xparse} 
\DeclarePairedDelimiterX{\set}[1]{\{}{\}}{\setargs{#1}}
\NewDocumentCommand{\setargs}{>{\SplitArgument{1}{;}}m}
{\setargsaux#1}
\NewDocumentCommand{\setargsaux}{mm}
{\IfNoValueTF{#2}{#1} {#1\,\delimsize|\,\mathopen{}#2}}%{#1\:;\:#2}

% Some common symbols
\newcommand{\veq}{\mathrel{\rotatebox{90}{$=$}}}
\newcommand{\vneq}{\mathrel{\rotatebox{90}{$\neq$}}}
\newcommand{\vect}[1]{\vv{\mathbf{#1}}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\rank}{\operatorname{rank}}

\lhead{MATH 425}
\chead{Homework 6}
\rhead{Sitthisarnwattanachai}

\title{MATH 425 Homework 6}
\author{mosguinz}
\date{November 2024}

\begin{document}

\section*{Question 1}

\subsection*{Part A}

If $\lambda$ is an eigenvalue of $A$, then $A\vect{v}=\lambda\vect{v}$ for an eigenvector $\vect{v}\neq\vect{0}$. $c\lambda+d$ is an eigenvalue of $B=cA+dI$ if $B\vect{v}=(c\lambda+d)\vect{v}$.

Since
\begin{align*}
    B\vect{v} &= (cA+dI)\vect{v} \\
    &= cA\vect{v} + dI\vect{v} \\
    &= c\lambda\vect{v} + d\vect{v} & \because A\vect{v}=\lambda\vect{v}\\
    &= (c\lambda+d)\vect{v},
\end{align*}
$(c\lambda+d)\vect{v}$ is an eigenvalue of $B$.

\subsection*{Part B}

If $\lambda$ is an eigenvalue of $A$, then $A\vect{v}=\lambda\vect{v}$. For $A^k$, consider $k=2$:
$$
A^2\vect{v} = A(A\vect{v}) = A(\lambda\vect{v}) = \lambda(A\vect{v}) = \lambda(\lambda\vect{v}) = \lambda^2\vect{v}.
$$

Then, for any positive integer $k$, we have that:
\begin{align*}
    A^k\vect{v} = (\underbrace{A\cdot A \cdots A}_{\text{$k$ terms}})\vect{v}
    &= (\underbrace{A\cdot A \cdots A}_{\text{$k-1$ terms}})(A\vect{v}) \\
    &= (\underbrace{A\cdot A \cdots A}_{\text{$k-1$ terms}})(\lambda\vect{v}) \\
    &= \lambda(\underbrace{A\cdot A \cdots A}_{\text{$k-2$ terms}})(A\vect{v}) \\
    &= \lambda(\underbrace{A\cdot A \cdots A}_{\text{$k-2$ terms}})(\lambda\vect{v}) \\
    &= \lambda^2(\underbrace{A\cdot A \cdots A}_{\text{$k-3$ terms}})(A\vect{v}) \\
\end{align*}
Hence, after each successive applications of $k$, we have that $A^k\vect{v}=\lambda^k\vect{v}$.

\subsection*{Part C}

If $\lambda$ is an eigenvalue of $A$, then $A\vect{v}=\lambda\vect{v}$. For $\lambda=0$, we have that $A\vect{v} = 0\vect{v}=\vect{0}$.

If $A$ is singular, then $A$ has a nontrivial kernel i.e., $\ker(A)\neq\set{\vect{0}}$. As such, there exists a nonzero vector $\vect{v}\in\ker(A)$. This means that the subspace containing eigenvectors (hereinafter, \textit{eigenspace}) corresponding to the eigenvalue $\lambda=0$ is precisely $\ker(A)$ and thus have the same dimension.

Conversely, $A$ must be singular for $\lambda=0$ to be its eigenvalue. If $A$ is nonsingular, then $A$ has a trivial kernel. This means that there exists no nonzero vector $\vect{v}$ such that $A\vect{v}=\vect{0}$.

\subsection*{Part D}

Let $A$ be an $n\times n$ matrix where each entry of $A$ is equal to one:
$$
A=\begin{pmatrix}
    1 & 1 & \cdots & 1 \\
    1 & 1 & \cdots & 1 \\
    \vdots & \vdots & \ddots & \vdots \\
    1 & 1 & \cdots & 1
\end{pmatrix}.
$$

Obviously, we first note that $\rank(A)=1$ and that $A$ has a nontrivial kernel. Thus $A$ is singular and by (c), we know that $\lambda=0$ is an eigenvalue of $A$.

By the rank--nullity theorem, the nullity of $A$ is $n-\rank(A)=n-1$. From (c), we found that the dimension of eigenspace corresponding to the eigenvalue $\lambda=0$ is the nullity of $A$. As such $\lambda=0$ is an eigenvalue of $A$ with multiplicity $n-1$. This means there exists one other nonzero eigenvalue.

Take $\vect{v} = \begin{pmatrix}
    1 & 1 & \cdots & 1
\end{pmatrix}^\top$, an $n\times1$ vector whose entries consists of ones. Since the sum of each rows of $A$ is $n$, we have that
$$
A\vect{v}
= \begin{pmatrix}
    1 & 1 & \cdots & 1 \\
    1 & 1 & \cdots & 1 \\
    \vdots & \vdots & \ddots & \vdots \\
    1 & 1 & \cdots & 1
\end{pmatrix}
\begin{pmatrix}
    1 \\ 1 \\ \vdots \\ 1
\end{pmatrix}
= \begin{pmatrix}
    n \\ n \\ \vdots \\ n
\end{pmatrix}
= n \begin{pmatrix}
    1 \\ 1 \\ \vdots \\ 1
\end{pmatrix}
= n\vect{v}.
$$

As such, $\lambda=n$ is an eigenvalue of $A$.

So, the eigenvalues of $A$ are $\lambda=0$ with the corresponding eigenvectors forming the subspace $\set{\vect{v}\in\R^n \mid A\vect{v}=\vect{0}}$ and $\lambda=n$ with the corresponding eigenvector $\begin{pmatrix}
    1 & 1 & \cdots & 1
\end{pmatrix}^\top$.

\subsection*{Part E}

If $\lambda$ is an eigenvalue of $A$, then $A\vect{v}=\lambda\vect{v}$. If $A$ is nonsingular, then applying $A^{-1}$ yields:
\begin{align*}
    A^{-1}A\vect{v} = A^{-1}\lambda\vect{v} \\
    \vect{v} = A^{-1}\lambda\vect{v} \\
    \frac{1}{\lambda}\vect{v} = A^{-1}\vect{v} \\
\end{align*}

Thus, $\lambda^{-1}$ is an eigenvalue of $A^{-1}$.

\section*{Question 2}

\subsection*{Part A}

Let $\vect{u}\in\R^n$ be a unit vector and let $A=\vect{u}\vect{u}^\top$. Since we construct $A$ in such a way that the columns are spanned by $\vect{u}$, $A$ has a rank of one.

From 1(c) and 1(d), we found that such a matrix (a rank-one, singular matrix) contains an eigenvalue of $\lambda=0$ with multiplicity $n-1$ and exactly one other nonzero eigenvalue.

To find the nonzero eigenvalue, take $\vect{v}=\vect{u}$. Then, $A\vect{v} = \lambda\vect{v} \implies \vect{u}\vect{u}^\top\vect{u} = \lambda\vect{u}$. Since $||\vect{u}||=1$ and $\vect{u}^\top\vect{u}=\langle\vect{u},\vect{u}\rangle=1$, we have that $\vect{u}=\lambda\vect{u}$. Thus, $\lambda=1$ is an eigenvalue of $A$ and the corresponding eigenvector is $\vect{u}$.

As such, the eigenvalues of $A$ are $\lambda=0$ with the corresponding eigenvectors forming the subspace $\set{\vect{v}\in\R^n\mid A\vect{v}=\vect{u}\vect{u}^\top\vect{v}=\vect{0}}$ and $\lambda=1$ with the corresponding eigenvector $\vect{u}$.

\subsection*{Part B}

If $\lambda$ is an eigenvalue of $H$, then $H\vect{v}=\lambda\vect{v}$. If $H=I-2\vect{u}\vect{u}^\top$ is a Householder matrix where $I$ is the identity matrix and $\vect{u}$ are unit vector.

First, consider the case where the vector lies in the span of the unit vector $\vect{u}$. Take $\vect{v}=\vect{u}$. Then,
\begin{align*}
    H\vect{u} &= \lambda\vect{u} \\
    &= (I-2\vect{u}\vect{u}^\top)\vect{u} \\
    &= \vect{u} - 2(\vect{u}\vect{u}^\top)\vect{u} \\
    &= \vect{u} - 2\vect{u} \\
    &= -\vect{u} &\therefore\lambda=-1.
\end{align*}

Thus, $\lambda=-1$ is an eigenvector of $H$.

Then consider the case where the vector is orthogonal to $\vect{u}$. That is, any vector $\vect{v}$ such that $\langle\vect{v},\vect{u}\rangle = \vect{u}^\top\vect{v} = 0$. We have that:
\begin{align*}
    H\vect{v} &= (I-2\vect{u}\vect{u}^\top)\vect{v} \\
    &= \vect{v} - 2(\vect{u}\vect{u}^\top)\vect{v} \\
    &= \vect{v} - 0 \\
    &= \lambda\vect{v} &\therefore\lambda=1.
\end{align*}

As such, the eigenvalues of $H=I-2\vect{u}\vect{u}^\top$ are $\lambda=-1$ and $\lambda=-1$.

\subsection*{Part C}

If $\lambda$ is an eigenvalue of $P$, then $P\vect{v}=\lambda\vect{v}$. Since $P^2=P$, then:
\begin{align*}
    P^2\vect{v} = P\vect{v} \\
    P(P\vect{v}) = \lambda\vect{v} \\
    \lambda(\lambda\vect{v}) = \lambda\vect{v} \\
    \lambda^2 = \lambda \\
    \lambda^2-\lambda = 0
\end{align*}

As such, the eigenvalues of $P$ are $\lambda=0$ and $\lambda=1$.

\section*{Question 3}

Let $A = \begin{pmatrix} 0 & c & -b \\ -c & 0 & a \\ b & -a & 0 \end{pmatrix}$.

Then,
\begin{align*}
    \det(A-\lambda I) &= \det\begin{pmatrix} 
        -\lambda & c & -b \\ 
        -c & -\lambda & a \\ 
        b & -a & -\lambda 
    \end{pmatrix}
    &= 0 \\
    &= (-\lambda) \begin{vmatrix} 
        -\lambda & a \\ 
        -a & -\lambda 
    \end{vmatrix}
    - c \begin{vmatrix} 
        -c & a \\ 
        b & -\lambda 
    \end{vmatrix}
    - b \begin{vmatrix} 
        -c & -\lambda \\ 
        b & -a 
    \end{vmatrix} &= 0\\
    &= \text{careful calculations...} &= 0\\
    &= (-\lambda)(\lambda^2 - a^2) - c(c\lambda - ab) - b(ac + \lambda b) &= 0\\
    &= -\lambda^3 + \lambda a^2 - c^2\lambda + abc - b^2\lambda - abc &= 0 \\
    &= -\lambda^3 - (c^2 + b^2)\lambda + a^2\lambda &= 0\\
    &= -\lambda \left( \lambda^2 - (a^2 + b^2 + c^2) \right) &= 0.
\end{align*}

And so, the eigenvalues are $\lambda=0$, $\lambda=-\sqrt{a^2 + b^2 + c^2}$, and $\lambda=\sqrt{a^2 + b^2 + c^2}$. Since we have three distinct eigenvalues, the three corresponding eigenvectors will be linearly independent and form a basis. Thus, $A$ is diagonalizable.

\section*{Question 4}

Let $S=\begin{pmatrix}
    -1 & 2 & 0 \\
    1 & -1 & 1 \\
    0 & 1 & 3
\end{pmatrix}$ and $\Lambda=\begin{pmatrix}
    2 & 0 & 0 \\
    0 & 2 & 0 \\
    0 & 0 & -2 \\
\end{pmatrix}$. Using the power of technology, we find $S^{-1} = \begin{pmatrix}
    2 & 3 & -1 \\
    \sfrac{3}{2} & \sfrac{3}{2} & -\sfrac{1}{2} \\
    -\sfrac{1}{2} & -\sfrac{1}{2} & \sfrac{1}{2}
\end{pmatrix}$.

Then, $S\Lambda S^{-1}=\begin{pmatrix}
    -1 & 2 & 0 \\
    1 & -1 & 1 \\
    0 & 1 & 3
\end{pmatrix}
\begin{pmatrix}
    2 & 0 & 0 \\
    0 & 2 & 0 \\
    0 & 0 & -2 \\
\end{pmatrix}
\begin{pmatrix}
    2 & 3 & -1 \\
    \sfrac{3}{2} & \sfrac{3}{2} & -\sfrac{1}{2} \\
    -\sfrac{1}{2} & -\sfrac{1}{2} & \sfrac{1}{2}
\end{pmatrix}
= \begin{pmatrix}
     6 & 6  & -2 \\
    -2 & -2 & 0 \\
     6 & 6  & -4
\end{pmatrix}$ is a matrix with eigenvalues $0$, $2$, and $-2$ with the corresponding eigenvectors $\begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix}, \begin{pmatrix} 2 \\ -1 \\ 1 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \\ 3 \end{pmatrix}$.

\section*{Question 5}

type this shit out

\section*{Question 6}

Refer to Section \code{\%\% Question 6} in the \code{math425hw6.m} file for the relevant code.

\end{document}
